# 对于第一轮知识库数控检测的报告以及改进建议

## 回答准确性

### RAG回答的准确性直接取决于三个因素：
- 检索到的知识条数是否充分
- 知识库的中的内容是否完备
- 模型的预训练资料是否涵盖

**经过测试**
-   目前模型部署上下文大约 **15360** tokens，约 **8000** 个中文汉字，因此检索的知识条数被限制在8条左右。
当检索的文本超出上下文长度时，语言模型不会进行回答。当模型回复+检索文本超出上下文长度时，超出部分会直接截断。
    
    对话历史也是上下文的主要占用。RAG可以认为是模型的长期记忆，对话历史则是模型的短期记忆。

    上下文长度受制于显存大小，因此改进空间有限。
-   在十轮的回答中，其中七轮模型并未从检索内容中找到决定性答案。可能原因如下：
    - 提问语言差异：例如FANUC被直译为发那科时，结论可能有所不同。因此需要中英文资料相互补充。
    - 资料储备不足：当未能从资料检索到关键字时，显然无法给出决定性回答。但是资料无法穷尽所有情况。
因此在本次测试中，当模型无法根据已有资料作答时，被允许在说明
“根据知识库中已有的信息无法回答该该问题, 以下回答由模型自主生成,仅供参考”
后给出自主回答。 因此模型本身的知识面决定了在资料不足时，能否对专业名词给出合理的回答。

## 回复生成速度

### 内容生成主要经过以下过程：
嵌入模型将问题切分为向量->嵌入模型检索->检索内容填充至语言模型->语音模型流式生成内容

当语言模型流式输出时，对于时间的感知明显减弱。因此主要等待时间在前三个部分。

在测试中，RAG检索条数为 **8** 条，知识匹配分数阈值 **0.8**(当阈值为2时，对于检索到的内容不作筛选),平均检索时长约为 **80**秒。

(当显卡无法支撑模型并发处理请求时，连续的两次请求，后者的等待时间明显变长)

#### 推测主要时长在第二个过程。仍需验证。

(目前程序会在进入第三过程时Complete知识匹配，并开始流式输出。因此真正意义上的检索时间只有第一二部分)

## 尝试方向(暂定)
- 建立缓存，在一次会话中被检索后筛选出的信息加入缓存，若下一次查询命中则即刻回答。

