亚龙大模型参数报告
===
## 基准模型

目前使用并且考虑长期使用的模型为**gpt-oss-20B**。

该模型在RAG问答方面表现良好，模型回答风格上更倾向于助手和导师，贴合使用场景，参数量较为甜点，推理速度理想。

此外遵循指令的能力远超qwen系列模型，在模型的分词器上使用了更加先进的架构，以及部署上使用了更加先进的量化策略。

目前来看，gpt-oss-20B是最适合的基准模型选择。

## 建议的部署配置

该配置适用于峰值200人以内同时使用，可以提供较为流畅的使用体验：

- **CPU**: 需要单核较强，主要算力用于嵌入模型的前期分词计算。

- **内存**：要求不高，显存不足时可以用于部署嵌入模型，但是计算效率仍然够用。

- **显卡**: 显存80G左右，备选，双卡l40s 48G 共10w，单卡A100 80G 共5w。前者性能更强。

- **硬盘**：主要用于存放用户数据和对话历史以及附件。可以使用MinIO作为对象存储，后期存储可随时扩展，也可以分布式存储，因此可以不用一次性用太多。机械硬盘也可以满足以上需求。

使用双卡l40s**预计**在**单请求**生成速度为**600tokens/s**以上，面对**200并发**时仍然可以保持在**50tokens/s**左右。
A100方案预估大约降低30%。

## 目前的开发配置

显卡: 4090 24G

模型**单请求**生成速度大约为**60tokens/s**,是一个较快的速度。

## 亚龙大模型的测试报告

### 题目来源

本次测试的试题来自于AI生成的来自4个文件的57道题目，并且携带参考答案。

这里的部分题目由于AI幻觉，无法从文档中找到确切的答案，可借此观察对普遍问题的回答能力以及幻觉。

### 测试方法
第一轮在未装填补丁的情况下测试，使用嵌入模型计算模型回答与参考答案的相似度。

第二轮为相似度较低的部分回答增加了补丁，再使用嵌入模型计算相似度。

最终将测试结果交由AI进行整理并且重新打分。

### 测试结果
测试数据的源文件请见目录source_file.

测试结果数据请见[yalong_test_results.csv](yalong_test_results.csv)或[yalong_test_results.xlsx](yalong_test_results.xlsx)

详情请见报告[AI对检索结果的对比分析.md](AI%E5%AF%B9%E6%A3%80%E7%B4%A2%E7%BB%93%E6%9E%9C%E7%9A%84%E5%AF%B9%E6%AF%94%E5%88%86%E6%9E%90.md)

注意，这里的相似度并不能代表准确性，也不能完全代表回答的好坏，仅用于初步筛选减少工作量以及填补数据空白。

### 简单总结
总的来说，亚龙大模型目前对于普遍的问题和知识库内的问题有较强的回答能力，对于补丁问题则有相对完美并且稳定的回答能力。

得益于该基准模型强大的指令遵循能力，仅使用提示词便可较好地约束对未知问题以及无法作答问题的幻觉。